<!doctype html>
<html>
<style>
	.container{
		width: 1200px;
		height: 800px;
		margin: auto;
		text-align: center;
	
				
	}
	.paper_title{
		font-size: 22px;
		color: green;
		width: 1000px;
		float: left;
		position: relative;
		top: 200px;
	}
	.paper_image{
		float: left;
		position: relative;
		left: 18px;
		top: 250px;	
	}
	.paper_time{
		color: gainsboro;
		width: 300px;
		float: left;
		font-size: 14px;
		position: absolute;
		top: 500px
		
		
		
	}
	.paper_info{
		width: 900px;
		text-align: left;
		position: relative;
		top: 250px;
		left: 70px;
		float:left;
		font-size: 18px;
		line-height: 30px;
		font-size: 15px
	}
 .bottom_info {
    width: 100%;
    height: 150px;
    background-color: white;
	float: left;
	margin-top: 500px;
  }
	#group_info{
		font-size: 15px;

		margin-top: 30px;
		float: left;
		margin-left: 200px;
		
	}
#group_detail_info{
		clear: both;
		font-size: 15px;
		margin-top: 30px;
		float: left;
		margin-left: 200px;

	}
	.image_logo{

		margin-top: 2px;
	}
	.return_index{
		color:green;
		float: left;
		position: relative;
		top: 270px;
		left: 370px;
		
	}
	.return_index_a{
		text-decoration: none;
		color: green;
	}
	.return_index_a:hover{
		text-decoration: underline;
		color: darkgreen;
	}
	.project_leaders{
		 color:green;
		font-size: 22px;
		text-align:left;
		width: 1200px;
		float: left;
		position: relative;
		top: 300px;
	
		
	}
	.project_leaders_name{
		color:black;
		font-size: 16px;
		text-align:left;
		width: 1200px;
		float: left;
		position: relative;
		top: 320px;
		margin-bottom: 50px
	
	}
	.project_example{
		 color:green;
		font-size: 22px;
		text-align:left;
		width: 1200px;
		float: left;
		position: relative;
		top: 300px;
	}
	.project_example_images{
		width: 1200px;
		float: left;
		position: relative;
		top: 300px;
		margin-top: 20px;
		
	}
	.example_text{
		width:1200px;
		text-align: center;
		font-size: 15px;
		line-height: 30px;
		float: left;
		margin-bottom: 50px
		
		
	}

</style>
<head>
<meta charset="utf-8">
<title>paper_info</title>
</head>

<body>
		<div class="container">
				<div class="paper_title">CLIP-Driven Universal Model for Tumor Detection Based on Magnetic Resonance Images</div>
				<div class="paper_image"><img src="zhangzhuoneng_research_image.jpg"  width="300px" height="197px"></div>
				<div class="paper_time">Published Wed 06 September 2023</div>
				<div class="paper_info">
					Tumor is one of the main causes of death in humans, and early detection and discovery of tumors through imaging means is crucial for patient treatment and prognosis. Magnetic Resonance Imaging (MRI) with an advantage of non-invasive, no radiation, and high spatial resolutions, which has been recognized as an important tool for screen and detection of tumor.
					Therefore, Our main research objective is to develop an expansive unified model，specifically grounded in the analysis of magnetic resonance (MR) tumor images. This ambitious undertaking aims to furnish a multifaceted solution, concurrently addressing various pivotal tasks integral to tumor characterization. These tasks encompass, but are not limited to, precise segmentation, nuanced classification discerning between benign and malignant manifestations, and the sophisticated classification of tumors based on molecular attributes. The overarching objective is to devise a model of notable sophistication and versatility, capable of comprehensively enhancing the diagnostic capabilities within the realm of tumor analysis and contributing substantively to the field of medical imaging research.
					
					The specific research route is shown in fig 2, specifically, the universal model supports multi MR input forms, such as T1, T1w, T2, Flair, DWI, DCE, and ADC. In addition, it also supports multiple organ sites, such as brain, chest, and abdomen. In output part, the universal model supports different tasks, such as segmentation of tumor, classification of benign and malignant of tumor, classification of tumor molecular, and prediction of biochemical recurrence.
					
				
				</div>
			
				
				<div style="margin-top: 100px; float: left">
					<div class="paper_title">An Explainable MRI Framework for Breast Tumor Using Amide Proton Transfer Weighted Imaging</div>
					<div class="paper_image"><img src="yqh_example_1.png"  width="300px" height="197px"></div>
					<div class="paper_time">Published Wed 06 September 2023</div>
					<div class="paper_info">
						Breast cancer is a malignant disease that endangers women's health. Early detection and early treatment are important means to improve the survival rate of breast cancer patients. Magnetic resonance imaging (MRI) breast examination has high safety and is suitable for routine breast screening.<p></p>
						 MRI is one of the internationally recognized effective methods for breast cancer detection. It has the characteristics of soft tissue resolution and high spatial resolution. However, it has the problems of uneven gray level and fuzzy boundary, which makes it difficult to segment the tumor region in clinical application.<p></p>
a
						APT image sequences have obvious APTw effects in breast tumors and their surrounding glandular tissues, so we propose an interpretable breast tumor segmentation network based on multi-task learning. This method combines APT parameter map and pathological data to assist tumor segmentation task. This paper uses convolutional neural network to extract the features of APT image sequences, analyzes the contribution of different pulse frequencies to segmentation, and improves the interpretability of the model.<p></p>
						The results of tumor segmentation and classification by APT image sequences show that the importance of saturated images with different pulse frequencies to segmentation results is different, and the frequency used in imaging can be selected according to the importance, which is beneficial to reduce the imaging time. The segmentation results obtained by combining the APT parametric map and pathological data are better than those obtained by using only APT image sequences, indicating that the APT effect helps to improve the accuracy of tumor segmentation.<p></p>
						The proposed deep learning multi-task model combined with APT image sequence can improve the accuracy of breast tumor segmentation, which provides a new idea for breast tumor diagnosis.
					
				
				</div>
			
				</div>
				<div class="return_index"><a  class="return_index_a" href="../research_frame.html" target="_blank" >← Back to overview</a></div>
				<div class="project_leaders">Project  leaders</div>
				<div class="project_leaders_name">ZhuonengZhang  <P></P> QiuhuiYang</div>	
			
				
				<div class="project_leaders">Partner Organisations</div>
				<div class="project_leaders_name">杭州市第一人医院 <P></P>上海长海医院</div>
					
			
		
			
				<div class="project_example">Project Example</div>
				<div class="project_example_images" style="margin-bottom: 50px">
					<div class="project_example_images_"><img src="example_1.png"  width="500px" ></div>
					<div class="example_text">Comparison of different models in segmentation of tumor</div>
					<div class="project_example_images_" style="margin-top: 50px"><img src="yqh_example_1.png"  width="500px"  ></div>
					
					
					
			</div>
			
		</div>
	
	
	 <div class="bottom_info"> 
				  <div  style="width:1200px;height: 150px;margin: auto">
				  		<div id="group_info"> © Generalized Electric Medicine 2023 of Macao polytechnic university.</div>
						<div id="group_detail_info">The Generalized Electric Medicine is part of the Macao polytechnic university.</div>
						<div class="image_logo"> <img src="../gem_logopng.png"  style="height:140px;right: 0" ></div>
			       </div>
			  </div>
</body>
</html>
